{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../\")\n",
    "sys.path.append('../../')\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from itertools import cycle\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from potential_flows import transforms, potential, encoders, data, flow\n",
    "from potential_flows.data import get_dataset, create_custom_dataset\n",
    "from flow.arguments import set_seed, parse_arguments, parse_notebook_arguments, get_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we study the dimension and sample size complexity of dual and minimax algorithms. \n",
    "\n",
    "1. For **dimension dependence**, we run the Trainer for both methods for 10 steps and report the average CPU time.\n",
    "\n",
    "2. For **training sample size dependence**, we report the average time for evaluating the objective function for both methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "args = parse_notebook_arguments()\n",
    "\n",
    "dim_list = [int(10*(n+1)) for n in range(100)]\n",
    "time_list = torch.zeros(len(dim_list))\n",
    "args.num_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/medhaaga/miniconda3/envs/nsf/lib/python3.10/site-packages/torch/autograd/__init__.py:394: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "100%|██████████| 10/10 [00:07<00:00,  1.39it/s]\n",
      "100%|██████████| 10/10 [00:13<00:00,  1.39s/it]\n",
      "100%|██████████| 10/10 [00:20<00:00,  2.00s/it]\n",
      "100%|██████████| 10/10 [00:26<00:00,  2.64s/it]\n",
      "100%|██████████| 10/10 [00:32<00:00,  3.25s/it]\n",
      "100%|██████████| 10/10 [00:38<00:00,  3.83s/it]\n",
      "100%|██████████| 10/10 [00:44<00:00,  4.47s/it]\n",
      "100%|██████████| 10/10 [00:48<00:00,  4.88s/it]\n",
      "100%|██████████| 10/10 [00:54<00:00,  5.45s/it]\n",
      "100%|██████████| 10/10 [01:00<00:00,  6.03s/it]\n",
      "100%|██████████| 10/10 [01:05<00:00,  6.53s/it]\n",
      "100%|██████████| 10/10 [01:10<00:00,  7.08s/it]\n",
      "100%|██████████| 10/10 [01:17<00:00,  7.73s/it]\n",
      "100%|██████████| 10/10 [01:21<00:00,  8.16s/it]\n",
      "100%|██████████| 10/10 [01:27<00:00,  8.72s/it]\n",
      "100%|██████████| 10/10 [01:33<00:00,  9.30s/it]\n",
      "100%|██████████| 10/10 [01:37<00:00,  9.75s/it]\n",
      "100%|██████████| 10/10 [01:40<00:00, 10.08s/it]\n",
      "100%|██████████| 10/10 [01:30<00:00,  9.09s/it]\n",
      "100%|██████████| 10/10 [01:37<00:00,  9.76s/it]\n",
      "100%|██████████| 10/10 [01:37<00:00,  9.75s/it]\n",
      "100%|██████████| 10/10 [01:42<00:00, 10.24s/it]\n",
      "100%|██████████| 10/10 [01:46<00:00, 10.62s/it]\n",
      "100%|██████████| 10/10 [01:56<00:00, 11.63s/it]\n",
      "100%|██████████| 10/10 [02:23<00:00, 14.32s/it]\n",
      "100%|██████████| 10/10 [02:37<00:00, 15.79s/it]\n",
      "100%|██████████| 10/10 [02:51<00:00, 17.12s/it]\n",
      "100%|██████████| 10/10 [03:01<00:00, 18.17s/it]\n",
      "100%|██████████| 10/10 [03:09<00:00, 18.98s/it]\n",
      "100%|██████████| 10/10 [03:13<00:00, 19.35s/it]\n",
      "100%|██████████| 10/10 [03:04<00:00, 18.48s/it]\n",
      "100%|██████████| 10/10 [03:10<00:00, 19.10s/it]\n",
      "100%|██████████| 10/10 [03:14<00:00, 19.47s/it]\n",
      "100%|██████████| 10/10 [03:42<00:00, 22.24s/it]\n",
      "100%|██████████| 10/10 [04:05<00:00, 24.58s/it]\n",
      "100%|██████████| 10/10 [04:10<00:00, 25.06s/it]\n",
      "100%|██████████| 10/10 [04:17<00:00, 25.78s/it]\n",
      "100%|██████████| 10/10 [04:21<00:00, 26.19s/it]\n",
      "100%|██████████| 10/10 [04:27<00:00, 26.80s/it]\n",
      "100%|██████████| 10/10 [04:35<00:00, 27.56s/it]\n",
      "100%|██████████| 10/10 [04:40<00:00, 28.05s/it]\n",
      " 10%|█         | 1/10 [00:28<04:19, 28.83s/it]"
     ]
    }
   ],
   "source": [
    "## Dual Method ##\n",
    "\n",
    "# running 10 training steps for each dimension\n",
    "\n",
    "for i,d in enumerate(dim_list):\n",
    "    \n",
    "    # create datasets and dataloaders for dimension d\n",
    "\n",
    "    args.data_shape = (int(d),)\n",
    "    dataset_x, dataset_y = get_dataset(args, split=\"train\")\n",
    "    test_x, test_y = get_dataset(args, split=\"test\")\n",
    "\n",
    "    data_loader_X = DataLoader(dataset_x, batch_size=args.batch_size, shuffle=True)\n",
    "    data_loader_Y = DataLoader(dataset_y, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "    # create flow\n",
    "\n",
    "    tail_bound = torch.max(torch.cat([torch.abs(dataset_x.data), torch.abs(dataset_y.data)]))\n",
    "    potential_flow = potential.ICRQ(tail_bound=args.tail_factor*tail_bound, num_bins=args.num_bins, data_shape=args.data_shape)\n",
    "\n",
    "    # train for 10 steps\n",
    "\n",
    "    OT_Trainer = flow.DualOT_Trainer(potential_flow, args, dataset_x=data_loader_X, dataset_y=data_loader_Y, test_x=test_x, test_y=test_y)\n",
    "    \n",
    "    start = time.perf_counter(), time.process_time()\n",
    "    OT_Trainer.learn()\n",
    "    stop = time.perf_counter(), time.process_time()\n",
    "    \n",
    "    time_list[i] = stop[1] - start[1]\n",
    "\n",
    "torch.save({'dim': dim_list, 'time': time_list/args.num_steps}, 'dual_dimension_complexity.pt')\n",
    "\n",
    "# plotting dimension vs per training step time in seconds\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.plot(dim_list, time_list/args.num_steps)\n",
    "plt.xlabel('Dimension')\n",
    "plt.ylabel('Time per train step')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Minmax Method ##\n",
    "\n",
    "# running 10 training steps for each dimension\n",
    "\n",
    "for i,d in enumerate(dim_list):\n",
    "    \n",
    "    # create dataset and dataloaders for dimension d\n",
    "    \n",
    "    args.data_shape = (int(d),)\n",
    "    dataset_x, dataset_y = get_dataset(args, split=\"train\")\n",
    "    test_x, test_y = get_dataset(args, split=\"test\")\n",
    "\n",
    "    data_loader_X = DataLoader(dataset_x, batch_size=args.batch_size, shuffle=True)\n",
    "    data_loader_Y = DataLoader(dataset_y, batch_size=args.batch_size, shuffle=True)\n",
    "    \n",
    "    # create potential flows for f and g\n",
    "\n",
    "    tail_bound = torch.max(torch.cat([torch.abs(dataset_x.data), torch.abs(dataset_y.data)]))\n",
    "    potential_flow_x = potential.ICRQ(tail_bound=args.tail_factor*tail_bound, num_bins=args.num_bins, data_shape=args.data_shape)\n",
    "    potential_flow_y = potential.ICRQ(tail_bound=args.tail_factor*tail_bound, num_bins=args.num_bins, data_shape=args.data_shape)\n",
    "\n",
    "    ## train\n",
    "\n",
    "    OT_Trainer = flow.MinmaxOT_Trainer(potential_flow_x, potential_flow_y, args, dataset_x=data_loader_X, dataset_y=data_loader_Y, test_x=test_x, test_y=test_y)       \n",
    "    \n",
    "    start = time.perf_counter(), time.process_time()\n",
    "    OT_Trainer.learn()\n",
    "    stop = time.perf_counter(), time.process_time()\n",
    "\n",
    "    time_list[i] = stop[1] - start[1]\n",
    "    print(f'Dimension: {d}, Time: {time_list[i]}')\n",
    "    \n",
    "torch.save({'dim': dim_list, 'time': time_list/args.num_steps}, 'minmax_dim_complexity.pt')\n",
    "\n",
    "plt.plot(dim_list, time_list/args.num_steps)\n",
    "plt.xlabel('Dimension')\n",
    "plt.ylabel('Time per train step')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample complexity\n",
    "\n",
    "args.data_shape = (2,)\n",
    "n_list = [int(1000*(n+1)) for n in range(100)]\n",
    "time_list = np.zeros(len(n_list))\n",
    "\n",
    "# create potential flows for f and g\n",
    "\n",
    "potential_flow_x = potential.ICRQ(tail_bound=2, num_bins=args.num_bins, data_shape=args.data_shape)\n",
    "potential_flow_y = potential.ICRQ(tail_bound=2, num_bins=args.num_bins, data_shape=args.data_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running 10 training steps for each dimension\n",
    "\n",
    "for i,n in enumerate(tqdm(n_list)):\n",
    "    \n",
    "    args.num_samples = int(n)\n",
    "    dataset_x, dataset_y = get_dataset(args, split=\"train\")\n",
    "    test_x, test_y = get_dataset(args, split=\"test\")\n",
    "\n",
    "    data_loader_X = DataLoader(dataset_x, batch_size=args.batch_size, shuffle=True)\n",
    "    data_loader_Y = DataLoader(dataset_y, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "    OT_Trainer = flow.DualOT_Trainer(potential_flow, args, dataset_x=data_loader_X, dataset_y=data_loader_Y, test_x=test_x, test_y=test_y)\n",
    "    \n",
    "    start = time.perf_counter(), time.process_time()\n",
    "    OT_Trainer.objective(dataset_x.data, dataset_y.data)\n",
    "    stop = time.perf_counter(), time.process_time()\n",
    "    \n",
    "    time_list[i] = stop[1]-start[1]\n",
    "\n",
    "torch.save({'dim': n_list, 'time': time_list/args.num_steps}, 'dual_N_complexity.pt')\n",
    "\n",
    "# plotting dimension vs per training step time in seconds\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.plot(n_list, time_list/args.num_steps)\n",
    "plt.xlabel('\"Sample size (n)')\n",
    "plt.ylabel('Average time for objective evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Minmax Method ##\n",
    "\n",
    "# evaluating the objective 10 times for each sample size\n",
    "\n",
    "for i,d in enumerate(n_list):\n",
    "    \n",
    "    # create dataset and dataloaders for dimension d\n",
    "    \n",
    "    args.num_samples = int(n)\n",
    "    dataset_x, dataset_y = get_dataset(args, split=\"train\")\n",
    "    test_x, test_y = get_dataset(args, split=\"test\")\n",
    "\n",
    "    data_loader_X = DataLoader(dataset_x, batch_size=args.batch_size, shuffle=True)\n",
    "    data_loader_Y = DataLoader(dataset_y, batch_size=args.batch_size, shuffle=True)\n",
    "    \n",
    "    ## train\n",
    "\n",
    "    OT_Trainer = flow.MinmaxOT_Trainer(potential_flow_x, potential_flow_y, args, dataset_x=data_loader_X, dataset_y=data_loader_Y, test_x=test_x, test_y=test_y)       \n",
    "    \n",
    "    start = time.perf_counter(), time.process_time()\n",
    "    OT_Trainer.objective(dataset_x.data, dataset_y.data)\n",
    "    stop = time.perf_counter(), time.process_time()\n",
    "    \n",
    "    time_list[i] = stop[1] - start[1]\n",
    "    print(f'Dimension: {d}, Time: {time_list[i]}')\n",
    "    \n",
    "torch.save({'dim': dim_list, 'time': time_list/args.num_steps}, 'minmax_dim_complexity.pt')\n",
    "\n",
    "plt.plot(n_list, time_list/args.num_steps)\n",
    "plt.xlabel('Dimension')\n",
    "plt.ylabel('Time per train step')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('nsf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a566d200f17f85181273f1df2cf49578138f48dbf3c5db771b8fbc824bec85a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
